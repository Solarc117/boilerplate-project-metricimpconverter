<------ Problem Solving Steps from Fireship --------->

1. Identify 
  - definte the issue
  - definte the context
  - why do we care to solve it?
2. Research & Define 
  - Google the problem; you're likely not the first one
  - Discuss w/other devs
  - Break problem down into smaller tasks
  - Determine what tools & apis to use 
3. Pseudo-code
  - how do we implement our code?
  - don't worry about syntax
  - can write pseudo-code in a lang, if you're comfortable enough w/it
4. (optional) Test-Driven Development
  - Consider using Jest (a JS testing library)
  - Red, green, refactor process:
    a) write failing tests that describe what you're trying to do
    b) write code that makes your tests pass
    c) refactor/optimize tests/code
  - good specs help you catch issues much quicker than you could debug them
5. Implement Code
  - try to implement the first working prototype as quickly as possible: try to treat it like a hackathon & don't worry about the quality of the code
    * refactoring and cleaning imperfect code is easier than writing clean code from the get-go
6. Relax, sleep, & reflect on the code
  - take a break if you're stuck!
  - a few suggestions to improve code:
    a) improve readability
    b) add useful comments
    c) remove duplication
    d) optimize time/space complexities
    e) add error handling
    f) add caching
7. Keep practicing! Get feedback from other devs.

<!-------------------- END ------------------------->


📄⬇️ play around with different properties of res to use to verify a proper response
📄It would be neat to have a "full response" method in ConvertHandler that draws from its own methods to return all the properties that a response object would be expected to have, and call THAT method in the api file, instead of defining each property individually and returning an anonymous object with all of those properties.
📄I should consider adding messages to assertions (ex. assert.strictEquals(var, expect, MESSAGE)) if it improves readability and is worth the time investment.
📄I think, ultimately, what will matter more in terms of getting me a dev job will be what I have to show in terms of projects; not so much my fCC certifications. Therefore, I should make verifying fcctesting.js works my last task - still would be nice to get that certification, though, so I do still wanna see if it's doable within a reasonable amount of time.
📄render works with templates, like pug. sendFile sends file as is.
📄Should look up what my brother said about views being automatic, & why it doesn't work on this project.
📄Might wanna consider isolating separate api method handlers to their own files, and just invoke them all in the api.js file (ex. issue-tracker-api.js, metric-imperial-api.js, and require them)
📄In order to continue doing TDD, I should have a sign-in form, and set up tests for the database, form, & api
📄I should wait on impementing mdb until I SEE that I need it.

✨ ways to optimize learning that I should remember:
  - take short, mind-wandering breaks apart from ultradian breaks
  - use bedtime to estimate ultradian breaks for the day (TODAY: 09:00)
  - angle screen upward to trigger alertness
  - consciously try to blink less
  - do productive breaks during ultradian breaks (raise adrenalin, then: NSDR, walk, talk to someone, etc.)
  - implement perceptible, non-intrusive white noise during learning
  - MINIMIZE DISTRACTIONS


- ✅ issue a put request to the owners collection prior to the issue-tracker tests, to ensure a controlled environment.
- ✅ look at the role of the controller in mflix
  📄 the MoviesController calls the appropriate DAO methods for a method (eg. apiGetMovies => MovieDAO.getMovies), formats the obtained data in the expected json return object, and responds with said object. It does NOT handle errors; simply calls await DAO.METHOD().
- ✅ look at the role of router in mflix
  📄 the router file creates a new router instance, and sets up controller methods for different paths. It then exports the router.
- ✅ draw a diagram depicting how a put request from the test file is processed and results in a response -- include:
  📄 the data that is being passed on in every step
  📄 the way the data being passed on in every step 
  📄 the test file
  📄 the respective router
  📄 the respective controller
  📄 the respective controller method
  📄 the respective dao
  📄 the respective dao method
  📄 the respective db method
- 🎉🧱 code everything leading UP to the OwnersDAO put issues method:
  - ✅ create an issue-handler file in the controller folder
  - 🎉 create an IssueHandler class in the owners-handler file
  - create a putDocumentRequest method in the IssueHandler class, with params (req, res, next)
  - export the IssueHandler class
  - import the IssueHandler class in the api file
  - map issues/:owner/:project put requests to the IssueHandler class' putDocumentRequest method
  - log a message in the putDocumentRequest method of the OwnersHandler class
  - verify said msg is being logged; if not, debug
  - add documentation to the putDocumentRequest method
    📄 simply describe params, and write that the method handles the put request that is submitted by the test file by calling the dao object's putDocument method. Will edit the method's response, but for now will simply respond with whatever the dao method returns.
  - import the OwnersDAO object if it is not yet imported
  - call the OwnersDAO putDocument method, with the document passed, and store the return value in a response variable
  - return said response variable
- 🧱 add put request code to the OwnersDAO to make setup test pass:
  - ✅ find a way to connect to db BEFORE the router method setups: connect in server?
  - ✅ log a message with put requests
  - ✅ check how the data is being sent
  - ✅ receive data accordingly in the put request
  - ✅ look at how the mflix project accesses db in api
    📄 they use OOP to format apiCalls as methods, and use a different class called DAO (direct access object) which are the objects that access the db
  - ✅ look at how the DAO are connected to the index file
  - ✅ implement the mflix api db code
  - 

- ⚒️Create all of the functional tests in tests/issue-tracker.test.js:
  - Create an issue with every field: POST request to /api/issues/{project}
  - Create an issue with only required fields: POST request to /api/issues/{project}
  - Create an issue with missing required fields: POST request to /api/issues/{project}
  - View issues on a project: GET request to /api/issues/{project}
  - View issues on a project with one filter: GET request to /api/issues/{project}
  - View issues on a project with multiple filters: GET request to /api/issues/{project}
  - Update one field on an issue: PATCH request to /api/issues/{project}
  - Update multiple fields on an issue: PATCH request to /api/issues/{project}
  - Update an issue with missing _id: PATCH request to /api/issues/{project}
  - Update an issue with no fields to update: PATCH request to /api/issues/{project}
  - Update an issue with an invalid _id: PATCH request to /api/issues/{project}
  - Delete an issue: DELETE request to /api/issues/{project}
  - Delete an issue with an invalid _id: DELETE request to /api/issues/{project}
  - Delete an issue with missing _id: DELETE request to /api/issues/{project}

- ⚒️Complete the necessary routes in /routes/api.js for the /api/issues/{project}?open=true&assigned_to=Joe route:
  - get an issue, with the option to filter using asignees, reactions, or other things
  - post
  - PATCH
  - delete (alert user that gh rest api does not include this func)

- style issue-tracker's index page
- add navbar to issue-tracker
- compare fccTestingRoutes